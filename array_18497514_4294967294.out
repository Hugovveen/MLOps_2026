Using seed: 42
using device: cuda
paths are ok
pcam initialized
weighted sampler init
data loader initted
loaded data
Starting training for 3 epochs...
[LR] epoch=1 lr=0.001
[Train] epoch=1 step=0 loss=0.6986 acc=0.5312 grad_norm=2.6313
[Train] epoch=1 step=100 loss=0.6865 acc=0.5087 grad_norm=1.5588
[Train] epoch=1 step=200 loss=0.6960 acc=0.5210 grad_norm=3.1977
[Train] epoch=1 step=300 loss=0.7023 acc=0.5312 grad_norm=2.6173
[Train] epoch=1 step=400 loss=0.6746 acc=0.5425 grad_norm=2.4287
[Train] epoch=1 step=500 loss=0.7039 acc=0.5475 grad_norm=4.3071
[Train] epoch=1 step=600 loss=0.6393 acc=0.5557 grad_norm=2.1611
[Train] epoch=1 step=700 loss=0.6872 acc=0.5611 grad_norm=4.1202
[Train] epoch=1 step=800 loss=0.5962 acc=0.5690 grad_norm=2.4872
[Train] epoch=1 step=900 loss=0.6037 acc=0.5729 grad_norm=2.7664
[Train] epoch=1 step=1000 loss=0.7025 acc=0.5776 grad_norm=2.8400
[Train] epoch=1 step=1100 loss=0.6485 acc=0.5814 grad_norm=3.5476
[Train] epoch=1 step=1200 loss=0.7676 acc=0.5851 grad_norm=5.2626
[Train] epoch=1 step=1300 loss=0.6380 acc=0.5870 grad_norm=2.5410
[Train] epoch=1 step=1400 loss=0.6106 acc=0.5899 grad_norm=3.7402
[Train] epoch=1 step=1500 loss=0.8206 acc=0.5928 grad_norm=12.1541
[Train] epoch=1 step=1600 loss=0.6498 acc=0.5947 grad_norm=3.5356
[Train] epoch=1 step=1700 loss=0.6467 acc=0.5969 grad_norm=3.8330
[Train] epoch=1 step=1800 loss=0.6081 acc=0.5982 grad_norm=3.4176
[Train] epoch=1 step=1900 loss=0.6666 acc=0.6005 grad_norm=5.0021
[Train] epoch=1 step=2000 loss=0.6742 acc=0.6028 grad_norm=3.7386
[Train] epoch=1 step=2100 loss=0.5103 acc=0.6050 grad_norm=3.1080
[Train] epoch=1 step=2200 loss=0.6047 acc=0.6066 grad_norm=3.6269
[Train] epoch=1 step=2300 loss=0.6309 acc=0.6082 grad_norm=7.0206
[Train] epoch=1 step=2400 loss=0.7019 acc=0.6098 grad_norm=5.4212
[Train] epoch=1 step=2500 loss=0.6050 acc=0.6115 grad_norm=3.4934
[Train] epoch=1 step=2600 loss=0.5855 acc=0.6129 grad_norm=5.5509
[Train] epoch=1 step=2700 loss=0.6818 acc=0.6145 grad_norm=5.4191
[Train] epoch=1 step=2800 loss=0.6402 acc=0.6164 grad_norm=4.1667
[Train] epoch=1 step=2900 loss=0.5961 acc=0.6180 grad_norm=3.4696
[Train] epoch=1 step=3000 loss=0.6708 acc=0.6196 grad_norm=5.2889
[Train] epoch=1 step=3100 loss=0.6541 acc=0.6211 grad_norm=3.9696
[Train] epoch=1 step=3200 loss=0.5920 acc=0.6224 grad_norm=6.9577
[Train] epoch=1 step=3300 loss=0.5675 acc=0.6237 grad_norm=4.2570
[Train] epoch=1 step=3400 loss=0.6477 acc=0.6252 grad_norm=4.6563
[Train] epoch=1 step=3500 loss=0.5917 acc=0.6262 grad_norm=8.4104
[Train] epoch=1 step=3600 loss=0.5811 acc=0.6274 grad_norm=4.1969
[Train] epoch=1 step=3700 loss=0.6485 acc=0.6284 grad_norm=7.6338
[Train] epoch=1 step=3800 loss=0.6467 acc=0.6291 grad_norm=7.6375
[Train] epoch=1 step=3900 loss=0.6548 acc=0.6305 grad_norm=5.1112
